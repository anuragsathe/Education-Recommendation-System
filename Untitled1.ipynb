{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d5edce-3d8d-465b-888b-fb4b1f57944c",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d0263b1-91e6-4489-b3be-eba319d105c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   part_time_job  absence_days  extracurricular_activities  \\\n",
       "0          False             3                       False   \n",
       "1          False             2                       False   \n",
       "2          False             9                        True   \n",
       "3          False             5                       False   \n",
       "4          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"student-scores.csv\")\n",
    "df = df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ede42-d476-4377-a181-d1ac845cc665",
   "metadata": {},
   "source": [
    "# Drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3f4901-7784-4276-8257-5716fc598fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.drop(columns=['id','first_name','last_name','email'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578cc51-f152-4c7b-aaa8-428b18a41025",
   "metadata": {},
   "source": [
    "# Create new features from all score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "847e4b4b-d15b-4299-bad4-1c2ebd392389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_score\"] = df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] + df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19004d-7bca-4aa6-9f03-cb97ac5d4a97",
   "metadata": {},
   "source": [
    "# Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2eeaa011-0ca0-46a9-b191-74fb20a29f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Encode categorical columns using label encoder\n",
    "# df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# df['part_time_job'] = label_encoder.fit_transform(df['part_time_job'])\n",
    "# df['extracurricular_activities'] = label_encoder.fit_transform(df['extracurricular_activities'])\n",
    "# df['career_aspiration'] = label_encoder.fit_transform(df['career_aspiration'])\n",
    "# Define mapping dictionaries for categorical features\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "        'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "        'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "        'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "        'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "        'Real Estate Developer': 16\n",
    "    }\n",
    "# Apply mapping to the DataFrame\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "550f42ec-f217-43d7-af50-621a908339fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d49278e8-9e07-44ac-b5e1-f817aec82a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "9     169\n",
       "0     138\n",
       "11    126\n",
       "1     119\n",
       "16     83\n",
       "15     73\n",
       "13     68\n",
       "3      67\n",
       "14     63\n",
       "2      61\n",
       "6      59\n",
       "12     56\n",
       "8      39\n",
       "10     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e827c44-9814-4142-a273-aaa279adaa19",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629edfc-1be4-43e2-8252-e79978f176ba",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae19996c-a0d9-4067-9241-27bb522d0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2d0392d-1af0-449b-baea-e9c391116bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1b997-93b6-4770-8290-0a3479e1b224",
   "metadata": {},
   "source": [
    "# Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96c56a7a-642f-4d9a-afd3-0320901441da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e9f2e38-33d2-4d2b-91cc-29fbff7b95c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb024b7-8dfd-4823-b075-eaeea0ffa381",
   "metadata": {},
   "source": [
    "# Models Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f68f817a-c220-4670-82cd-d69049d40db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71738cf6-f9f8-46e2-80e4-3a645037a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.48739495798319327\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49        68\n",
      "           1       0.49      0.62      0.55        72\n",
      "           2       0.42      0.44      0.43        57\n",
      "           3       0.52      0.57      0.55        58\n",
      "           4       0.31      0.17      0.22        66\n",
      "           5       0.32      0.32      0.32        76\n",
      "           6       0.58      0.92      0.71        71\n",
      "           7       0.83      0.90      0.87        61\n",
      "           8       0.41      0.45      0.43        53\n",
      "           9       0.29      0.10      0.15        61\n",
      "          10       0.59      0.71      0.65        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.31      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.93      0.74        57\n",
      "          15       0.37      0.24      0.29        63\n",
      "          16       0.55      0.32      0.40        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.46      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  4  0  0  0  7  0  0  4  1 10  3  0  2  0  0  0]\n",
      " [ 2 45  0  0  0  7  0  0 13  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  1  0  0  2  0  4  1  2  2  4]\n",
      " [ 0  0  2 33  0  0  2  1  0  0  0  0  0  0 11  0  9]\n",
      " [ 6  5  7  3 11  9  7  1  2  3  0  3  3  2  1  2  1]\n",
      " [ 8  9  0  0  1 24  1  0  1  7  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  2 65  0  0  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 55  0  0  0  0  0  0  3  0  0]\n",
      " [ 4 18  0  0  0  1  0  0 24  0  6  0  0  0  0  0  0]\n",
      " [10  1  0  0  3  8  8  0  1  6  2  8  6  6  0  2  0]\n",
      " [ 8  2  0  0  1  0  4  0  2  1 45  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  4  6  3  0  4  1  0 24  1  3  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  2  0  3  0  0  0  5  1  1  4  4 27  0  5  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0 53  0  1]\n",
      " [ 4  3  3  0  5  8  1  2  0  0  2  7  4  7  1 15  1]\n",
      " [ 0  0 13 13  0  1  5  6  0  0  1  0  0  0  8  0 22]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.60      0.74      0.66        57\n",
      "           3       0.69      0.86      0.77        58\n",
      "           4       0.55      0.18      0.27        66\n",
      "           5       0.41      0.32      0.36        76\n",
      "           6       0.70      0.93      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.65      0.81      0.72        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.84      0.86      0.85        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.65      0.51      0.57        68\n",
      "          13       0.53      0.85      0.65        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.67      0.44      0.53        63\n",
      "          16       0.77      0.48      0.59        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.63      1071\n",
      "weighted avg       0.65      0.65      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  6  0  0  0  4  0  0  2  4  6  0  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  1  4  0  0  0  0  0  2  0  0  3  1]\n",
      " [ 0  0  2 50  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 5  8  7  1 12  7  5  2  1  7  0  2  4  3  1  1  0]\n",
      " [10  7  1  0  1 24  1  1  5 12  0  1  1 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 66  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  1  0  0  7  6  1  3 20  1  0  4  5  0  4  0]\n",
      " [ 2  1  4  0  0  0  0  0  0  1 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  2  1 27  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  1  8  0  2  0  1  1 35  4  4  0  4]\n",
      " [ 0  3  0  0  0  1  0  0  2  1  0  1  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  3  0  2  4  0  0  0  3  0  1  4  9  1 28  1]\n",
      " [ 0  0  9 15  0  2  2  1  0  0  0  0  1  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8366013071895425\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83        68\n",
      "           1       0.80      0.99      0.88        72\n",
      "           2       0.75      0.98      0.85        57\n",
      "           3       0.90      0.95      0.92        58\n",
      "           4       0.85      0.44      0.58        66\n",
      "           5       0.65      0.43      0.52        76\n",
      "           6       0.92      0.99      0.95        71\n",
      "           7       0.95      0.95      0.95        61\n",
      "           8       0.74      1.00      0.85        53\n",
      "           9       0.69      0.74      0.71        61\n",
      "          10       0.90      0.97      0.93        63\n",
      "          11       0.91      0.74      0.81        53\n",
      "          12       0.94      0.87      0.90        68\n",
      "          13       0.78      0.89      0.83        55\n",
      "          14       0.86      0.98      0.92        57\n",
      "          15       0.92      0.78      0.84        63\n",
      "          16       0.93      0.78      0.85        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.84      0.84      0.83      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[59  5  0  0  1  0  0  0  0  2  0  0  0  0  0  1  0]\n",
      " [ 1 71  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 3  2  5  0 29 10  1  0  3  4  3  0  2  0  1  0  3]\n",
      " [ 6  5  0  0  1 33  1  0  6 11  1  2  1  9  0  0  0]\n",
      " [ 0  0  0  0  0  1 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 58  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  2  0  0  1  3  0  2 45  0  1  1  0  0  2  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  0  0  3  1  1 39  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  0  1  0  1  0  1  0 59  1  2  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  3  0  0  0  0 49  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 2  3  1  0  0  2  0  0  0  2  0  1  0  3  0 49  0]\n",
      " [ 0  0  5  5  0  0  0  1  1  0  1  0  0  0  2  0 54]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6778711484593838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        68\n",
      "           1       0.73      0.78      0.75        72\n",
      "           2       0.63      0.86      0.73        57\n",
      "           3       0.60      0.81      0.69        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.35      0.14      0.21        76\n",
      "           6       0.83      0.92      0.87        71\n",
      "           7       0.90      0.72      0.80        61\n",
      "           8       0.67      0.91      0.77        53\n",
      "           9       0.44      0.48      0.46        61\n",
      "          10       0.81      0.92      0.86        63\n",
      "          11       0.71      0.64      0.67        53\n",
      "          12       0.71      0.79      0.75        68\n",
      "          13       0.69      0.80      0.74        55\n",
      "          14       0.82      0.89      0.86        57\n",
      "          15       0.65      0.62      0.63        63\n",
      "          16       0.78      0.58      0.67        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.66      0.69      0.67      1071\n",
      "weighted avg       0.66      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  2  0  0  0  3  0  0  1  8  6  0  0  0  0  2  0]\n",
      " [ 4 56  0  0  1  0  0  0  4  1  1  0  1  1  0  3  0]\n",
      " [ 0  0 49  1  0  0  0  0  0  0  2  0  0  0  1  1  3]\n",
      " [ 0  0  4 47  0  0  0  1  0  1  0  0  0  0  3  0  2]\n",
      " [ 4  5  5  5 11  6  6  1  2  7  1  1  6  1  1  1  3]\n",
      " [10  6  2  0  7 11  1  1  6  9  0  3  6 10  0  4  0]\n",
      " [ 0  0  1  2  0  0 65  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  3  2  0  1 44  0  2  0  1  2  1  1  1  2]\n",
      " [ 1  4  0  0  0  0  0  0 48  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  2  1  3  3  1  1  2 29  1  4  4  0  0  3  1]\n",
      " [ 2  0  2  0  0  0  0  0  0  1 58  0  0  0  0  0  0]\n",
      " [ 0  2  2  0  0  5  0  0  3  2  1 34  1  2  1  0  0]\n",
      " [ 1  1  2  2  0  0  1  0  0  2  1  1 54  0  0  3  0]\n",
      " [ 2  0  0  0  4  0  0  0  3  0  0  0  0 44  1  1  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  0  0  1  1 51  1  0]\n",
      " [ 2  1  1  4  2  1  1  0  3  2  0  4  0  3  0 39  0]\n",
      " [ 0  0  6 12  1  1  2  1  0  0  1  0  1  1  2  1 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6900093370681606\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64        68\n",
      "           1       0.77      0.85      0.81        72\n",
      "           2       0.65      0.70      0.67        57\n",
      "           3       0.78      0.74      0.76        58\n",
      "           4       0.47      0.41      0.44        66\n",
      "           5       0.43      0.25      0.32        76\n",
      "           6       0.87      0.85      0.86        71\n",
      "           7       0.94      0.79      0.86        61\n",
      "           8       0.80      0.91      0.85        53\n",
      "           9       0.51      0.57      0.54        61\n",
      "          10       0.78      0.86      0.82        63\n",
      "          11       0.55      0.66      0.60        53\n",
      "          12       0.65      0.75      0.70        68\n",
      "          13       0.65      0.75      0.69        55\n",
      "          14       0.84      0.91      0.87        57\n",
      "          15       0.56      0.49      0.53        63\n",
      "          16       0.78      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.69      1071\n",
      "   macro avg       0.69      0.70      0.69      1071\n",
      "weighted avg       0.68      0.69      0.68      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45  3  0  0  2  6  0  0  1  1  4  3  2  0  0  1  0]\n",
      " [ 2 61  0  0  0  1  0  0  2  2  0  1  1  2  0  0  0]\n",
      " [ 0  0 40  1  2  0  0  0  0  4  0  0  2  1  0  3  4]\n",
      " [ 0  0  2 43  2  0  0  2  0  0  0  0  1  0  5  0  3]\n",
      " [ 3  3  8  0 27  3  2  0  1  6  2  2  1  0  1  4  3]\n",
      " [ 7  6  0  0  6 19  1  0  3  7  1  6  5  8  0  7  0]\n",
      " [ 0  0  2  0  2  3 60  0  0  1  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  3  5  0  0 48  0  0  0  0  1  0  2  0  2]\n",
      " [ 2  0  0  0  0  0  0  0 48  1  1  1  0  0  0  0  0]\n",
      " [ 6  0  0  0  1  3  3  0  2 35  2  5  1  1  0  2  0]\n",
      " [ 0  1  0  0  0  1  0  0  1  5 54  0  1  0  0  0  0]\n",
      " [ 1  2  0  0  2  1  2  0  2  1  1 35  5  1  0  0  0]\n",
      " [ 0  1  0  1  4  1  0  0  0  3  1  1 51  0  1  3  1]\n",
      " [ 4  1  1  0  0  0  0  0  0  2  1  2  1 41  0  2  0]\n",
      " [ 0  0  1  1  0  0  0  0  0  0  0  0  2  0 52  0  1]\n",
      " [ 2  1  4  0  2  5  0  0  0  0  1  8  0  9  0 31  0]\n",
      " [ 0  0  4  6  2  1  1  1  0  0  0  0  2  0  1  2 49]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3099906629318394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.22      0.32        68\n",
      "           1       0.64      0.53      0.58        72\n",
      "           2       0.18      0.05      0.08        57\n",
      "           3       0.30      0.05      0.09        58\n",
      "           4       0.50      0.06      0.11        66\n",
      "           5       0.45      0.18      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.95      0.85      0.90        61\n",
      "           8       0.64      0.17      0.27        53\n",
      "           9       0.20      0.03      0.06        61\n",
      "          10       0.69      0.35      0.46        63\n",
      "          11       0.60      0.23      0.33        53\n",
      "          12       0.50      0.13      0.21        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.50      0.06      0.11        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.45      0.31      0.28      1071\n",
      "weighted avg       0.45      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  0  0  3  4  0  1  0  4  2  0 39  0  0  0]\n",
      " [ 0 38  0  0  0  2  3  0  3  0  0  0  2 24  0  0  0]\n",
      " [ 0  0  3  0  1  1 16  0  0  0  0  0  0 31  0  2  3]\n",
      " [ 0  0  0  3  0  0 15  1  0  0  0  0  0 23  3  0 13]\n",
      " [ 3  3  0  3  4  3 13  0  0  2  0  3  3 26  0  0  3]\n",
      " [ 4  6  0  0  1 14 12  0  0  2  0  1  1 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 52  0  0  0  0  0  3  0  0  2]\n",
      " [ 0  3  0  0  0  0  0  0  9  1  1  0  0 39  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  1 13  0  0  0  0 12  1 25  0  1  0]\n",
      " [ 0  1  7  0  0  0 21  0  1  0  1  0  9 27  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  1 44  0  4  2]\n",
      " [ 0  0  5  3  0  2 16  1  0  1  0  0  0 20  0  0 21]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.21942110177404295\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      1.00      0.27        68\n",
      "           1       1.00      0.61      0.76        72\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.24      0.37      0.29        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.06      0.09        63\n",
      "          11       1.00      0.36      0.53        53\n",
      "          12       0.13      0.28      0.18        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.19      0.80      0.30        69\n",
      "\n",
      "    accuracy                           0.22      1071\n",
      "   macro avg       0.17      0.20      0.14      1071\n",
      "weighted avg       0.17      0.22      0.15      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [28 44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6  0  0  0  0  0 27  0  0  0 24]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [36  0  0  0  0  0  2  0  0  0  2  0 15  0  0  0 11]\n",
      " [62  0  0  0  0  0 10  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 26  0  0  0  1  0 38  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [53  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [37  0  0  0  0  0 10  0  0  0  3  0 11  0  0  0  0]\n",
      " [51  0  0  0  0  0  6  0  0  0  4  0  2  0  0  0  0]\n",
      " [23  0  0  0  0  0  8  0  0  0  1 19  2  0  0  0  0]\n",
      " [19  0  0  0  0  0 13  0  0  0  1  0 19  0  0  0 16]\n",
      " [25  0  0  0  0  0 16  0  0  0  4  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [36  0  0  0  0  0 12  0  0  0  4  0  7  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0 55]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.746031746031746\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        68\n",
      "           1       0.79      0.97      0.87        72\n",
      "           2       0.63      0.88      0.74        57\n",
      "           3       0.81      0.90      0.85        58\n",
      "           4       0.48      0.15      0.23        66\n",
      "           5       0.50      0.46      0.48        76\n",
      "           6       0.85      0.99      0.92        71\n",
      "           7       0.97      0.95      0.96        61\n",
      "           8       0.78      0.98      0.87        53\n",
      "           9       0.49      0.44      0.47        61\n",
      "          10       0.90      0.95      0.92        63\n",
      "          11       0.80      0.62      0.70        53\n",
      "          12       0.76      0.60      0.67        68\n",
      "          13       0.65      0.87      0.74        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.75      0.57      0.65        63\n",
      "          16       0.82      0.68      0.75        69\n",
      "\n",
      "    accuracy                           0.75      1071\n",
      "   macro avg       0.74      0.75      0.73      1071\n",
      "weighted avg       0.73      0.75      0.73      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  4  0  0  2  5  0  0  0  1  0  2  0  0  0  0  0]\n",
      " [ 1 70  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 50  1  0  1  3  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 52  0  0  0  1  0  0  0  0  1  0  2  0  2]\n",
      " [ 5  4 11  0 10 10  1  0  1  8  2  1  3  4  1  3  2]\n",
      " [ 7  3  0  0  1 35  0  0  3 11  0  1  0 12  0  3  0]\n",
      " [ 0  0  0  0  1  0 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  3  0  2  5  3  0  4 27  3  0  4  1  0  4  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  1  3  2  0  3  4  0 33  0  2  0  0  0]\n",
      " [ 1  0  5  1  1  3  1  0  1  3  1  1 41  2  2  2  3]\n",
      " [ 1  1  2  0  0  1  0  0  2  0  0  0  0 48  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 3  2  2  0  1  7  0  0  1  1  1  3  1  4  0 36  1]\n",
      " [ 0  0  5  8  2  0  2  1  0  0  0  0  3  0  1  0 47]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.8272642390289449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.81      0.91      0.86        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.42      0.57        66\n",
      "           5       0.55      0.42      0.48        76\n",
      "           6       0.92      0.97      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.84      1.00      0.91        53\n",
      "           9       0.61      0.70      0.66        61\n",
      "          10       0.98      0.97      0.98        63\n",
      "          11       0.75      0.72      0.73        53\n",
      "          12       0.91      0.93      0.92        68\n",
      "          13       0.75      0.91      0.82        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.78      0.71      0.74        63\n",
      "          16       0.94      0.87      0.90        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  2  1  0  0  0  1  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  1  1  0  0  1  0  0  1  0  0  0  1]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 4  3  6  0 28  9  2  0  2  6  1  0  2  0  1  2  0]\n",
      " [ 8  4  0  0  0 32  0  0  2 10  0  4  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 57  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  4  1  0  2 43  0  3  2  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  0  1  0  0  0]\n",
      " [ 1  2  0  0  0  4  2  0  2  3  0 38  0  1  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1 63  0  2  0  0]\n",
      " [ 0  0  1  0  0  2  0  0  0  0  0  0  0 50  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 1  1  0  0  1  5  0  0  0  3  0  4  0  3  0 45  0]\n",
      " [ 0  0  2  5  1  0  0  1  0  0  0  0  0  0  0  0 60]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673a8d5-485f-469d-9046-b2fc2e6f52ef",
   "metadata": {},
   "source": [
    "# Models Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "570ac5e2-58a9-441a-8cdb-f0eb20adf619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8291316526610645\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83        68\n",
      "           1       0.79      0.99      0.88        72\n",
      "           2       0.75      0.96      0.85        57\n",
      "           3       0.90      0.95      0.92        58\n",
      "           4       0.77      0.41      0.53        66\n",
      "           5       0.58      0.38      0.46        76\n",
      "           6       0.93      0.99      0.96        71\n",
      "           7       0.95      0.92      0.93        61\n",
      "           8       0.78      0.98      0.87        53\n",
      "           9       0.71      0.72      0.72        61\n",
      "          10       0.91      0.97      0.94        63\n",
      "          11       0.87      0.75      0.81        53\n",
      "          12       0.87      0.88      0.88        68\n",
      "          13       0.75      0.93      0.83        55\n",
      "          14       0.88      0.98      0.93        57\n",
      "          15       0.90      0.73      0.81        63\n",
      "          16       0.90      0.83      0.86        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:  [[58  5  0  0  1  1  0  0  0  1  0  1  0  0  0  1  0]\n",
      " [ 0 71  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 2  2  8  1 27  9  1  0  2  5  1  2  2  0  1  0  3]\n",
      " [ 6  5  0  0  3 29  0  0  6  9  1  2  1 12  0  2  0]\n",
      " [ 0  0  0  0  0  0 70  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  3  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  1  0  0  2  2  0  2 44  3  0  4  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  2  5  0  0  2  1  0 40  0  2  0  0  0]\n",
      " [ 0  0  2  0  1  1  1  0  0  0  1  0 60  0  1  0  1]\n",
      " [ 0  0  1  0  0  0  0  0  2  0  0  0  0 51  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 4  3  2  0  1  2  0  0  0  1  0  1  0  3  0 46  0]\n",
      " [ 0  1  4  4  0  0  0  1  0  1  0  0  0  0  1  0 57]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35664829-b8a5-40d5-84e5-cca814cd91e6",
   "metadata": {},
   "source": [
    "# Single Input Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "641b5b69-598d-4cde-bbef-eb81108ed311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 12\n",
      "Model Prediction : 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[10])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4af2298-7804-4d9a-bb9f-9cc89b65ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 0\n",
      "Model Prediction : 0\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[300])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[300].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "144cc1da-c790-4ae1-b6f0-45ca3eba0b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 3\n",
      "Model Prediction : 3\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[23])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[23].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439beb14-6034-4fec-a6ab-e3ec8511a1b1",
   "metadata": {},
   "source": [
    "# Saving & Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a612df8-a8dc-4e47-addb-4d074fbff586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# Save files\n",
    "pickle.dump(scaler, open(\"Models/scaler.pkl\", 'wb'))\n",
    "pickle.dump(model, open(\"Models/model.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88333a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "485183ae-f078-46c6-873d-5aefbc3ce01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler, label encoder, and model\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5f742-bb00-44a3-a9e6-8dcc5088c6c8",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74ed66f3-51e5-48e0-9244-465654a0caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "475d55a4-0704-47b7-856c-6068871852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0cec9c5-694d-4adc-87cb-385cea37c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.73\n",
      "Unknown with probability 0.11\n",
      "Real Estate Developer with probability 0.05\n",
      "Government Officer with probability 0.05\n",
      "Stock Investor with probability 0.03\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36272c39-b5be-422c-88f8-91ab81f8bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Business Owner with probability 0.85\n",
      "Real Estate Developer with probability 0.09\n",
      "Unknown with probability 0.04\n",
      "Accountant with probability 0.02\n",
      "Game Developer with probability 0.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage 2\n",
    "final_recommendations = Recommendations(gender='male',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=4,\n",
    "                                        math_score=37,\n",
    "                                        history_score=33,\n",
    "                                        physics_score=48,\n",
    "                                        chemistry_score=61,\n",
    "                                        biology_score=59,\n",
    "                                        english_score=60,\n",
    "                                        geography_score=37,\n",
    "                                        total_score=335,\n",
    "                                        average_score=47.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bc5e768-be70-4aff-a245-eeffd46993c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.73\n",
      "Unknown with probability 0.11\n",
      "Real Estate Developer with probability 0.05\n",
      "Government Officer with probability 0.05\n",
      "Stock Investor with probability 0.03\n"
     ]
    }
   ],
   "source": [
    "# Example usage 3\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24cea84a-375c-4aad-872f-f63755d00eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "# sklear version in pychar production \n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "# in pycharm env install\n",
    "# pip install scikit-learn==1.3.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
